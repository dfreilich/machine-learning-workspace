{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from hw2_utils import run_model, get_CIFAR10_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Model1 (Simple Model) (CPU)\n",
    "\n",
    "### Some useful utilities\n",
    "\n",
    ". Remember that our image data is initially N x H x W x C, where:\n",
    "* N is the number of datapoints\n",
    "* H is the height of each image in pixels\n",
    "* W is the height of each image in pixels\n",
    "* C is the number of channels (usually 3: R, G, B)\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, which needs spatial understanding of where the pixels are relative to each other. When we input image data into fully connected affine layers, however, we want each data example to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in TensorFlow -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up. \n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Hinge loss function, and the Adam optimizer being used. \n",
    "\n",
    "Make sure you understand why the parameters of the Linear layer are 5408 and 10.\n",
    "\n",
    "### TensorFlow Details\n",
    "In TensorFlow, much like in our previous notebooks, we'll first specifically initialize our variables, and then our network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def model1(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = model1(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). \n",
    "\n",
    "* Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "* Optimizers: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "* BatchNorm: https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on one epoch\n",
    "While we have defined a graph of operations above, in order to execute TensorFlow Graphs, by feeding them input data and computing the results, we first need to create a `tf.Session` object. A session encapsulates the control and state of the TensorFlow runtime. For more information, see the TensorFlow [Getting started](https://www.tensorflow.org/get_started/get_started) guide.\n",
    "\n",
    "Optionally we can also specify a device context such as `/cpu:0` or `/gpu:0`. For documentation on this behavior see [this TensorFlow guide](https://www.tensorflow.org/tutorials/using_gpu)\n",
    "\n",
    "You should see a validation loss of around 0.4 to 0.6 and an accuracy of 0.30 to 0.4 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 14.6 and accuracy of 0.094\n",
      "Iteration 100: with minibatch training loss = 0.996 and accuracy of 0.28\n",
      "Iteration 200: with minibatch training loss = 0.691 and accuracy of 0.42\n",
      "Iteration 300: with minibatch training loss = 0.787 and accuracy of 0.31\n",
      "Iteration 400: with minibatch training loss = 0.615 and accuracy of 0.33\n",
      "Iteration 500: with minibatch training loss = 0.566 and accuracy of 0.28\n",
      "Iteration 600: with minibatch training loss = 0.446 and accuracy of 0.33\n",
      "Iteration 700: with minibatch training loss = 0.504 and accuracy of 0.42\n",
      "Epoch 1, Overall loss = 0.784 and accuracy of 0.306\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nav8fvpkxB7f+pGcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e43b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 0.452 and accuracy of 0.375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,y_out,mean_loss,X,y,is_training,X_train,y_train,1,64,100,train_step,True)\n",
    "        print('Validation')\n",
    "        run_model(sess,y_out,mean_loss,X,y,is_training,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Model 2 (Implement a specific model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete function `model2()` in `hw2_part3_cpu.py`, Then run the following 2 cells to test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hw2_part3_cpu import model2\n",
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define our input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# define model\n",
    "y_out = model2(X,y,is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you're doing the right thing, use the following tool to check the dimensionality of your output (it should be 64 x 10, since our batches have size 64 and the output of the final affine layer should be 10, corresponding to our 10 classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Now we're going to feed a random batch into the model \n",
    "# and make sure the output is the right size\n",
    "x = np.random.randn(64, 32, 32,3)\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\"\n",
    "        tf.global_variables_initializer().run()\n",
    "        ans = sess.run(y_out,feed_dict={X:x,is_training:True})\n",
    "        print(ans.shape)\n",
    "        print(np.array_equal(ans.shape, np.array([64, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the following from the run above \n",
    "\n",
    "`(64, 10)`\n",
    "\n",
    "`True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 GPU \n",
    "\n",
    "Starting from this section, you have to use the server. Copy your result of running `hw3_part3_gpu.py` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train data shape:  (49000, 32, 32, 3)\n",
    "Train labels shape:  (49000,)\n",
    "Validation data shape:  (1000, 32, 32, 3)\n",
    "Validation labels shape:  (1000,)\n",
    "Test data shape:  (10000, 32, 32, 3)\n",
    "Test labels shape:  (10000,)\n",
    "2018-03-21 00:10:38.601643: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
    "2018-03-21 00:10:39.046150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \n",
    "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
    "pciBusID: 0000:81:00.0\n",
    "totalMemory: 15.89GiB freeMemory: 15.60GiB\n",
    "2018-03-21 00:10:39.046220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:81:00.0, compute capability: 6.0)\n",
    "2018-03-21 00:10:41.540435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:81:00.0, compute capability: 6.0)\n",
    "Training\n",
    "Iteration 0: with minibatch training loss = 3.56 and accuracy of 0.094\n",
    "Iteration 100: with minibatch training loss = 2.09 and accuracy of 0.38\n",
    "Iteration 200: with minibatch training loss = 1.92 and accuracy of 0.34\n",
    "Iteration 300: with minibatch training loss = 2.13 and accuracy of 0.38\n",
    "Iteration 400: with minibatch training loss = 1.44 and accuracy of 0.55\n",
    "Iteration 500: with minibatch training loss = 1.16 and accuracy of 0.62\n",
    "Iteration 600: with minibatch training loss = 1.35 and accuracy of 0.48\n",
    "Iteration 700: with minibatch training loss = 1.7 and accuracy of 0.53\n",
    "Epoch 1, Overall loss = 1.74 and accuracy of 0.441\n",
    "Validation\n",
    "Epoch 1, Overall loss = 1.75 and accuracy of 0.486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Train Your own Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your best result of running `hw3_part3_mymodel.py` here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b63105d9e5b0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b63105d9e5b0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (myenv) [dfreilic@gpu015 dfreilic]$ python hw2_part3_mymodel.py\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(myenv) [dfreilic@gpu015 dfreilic]$ python hw2_part3_mymodel.py \n",
    "Train data shape:  (49000, 32, 32, 3)\n",
    "Train labels shape:  (49000,)\n",
    "Validation data shape:  (1000, 32, 32, 3)\n",
    "Validation labels shape:  (1000,)\n",
    "Test data shape:  (10000, 32, 32, 3)\n",
    "Test labels shape:  (10000,)\n",
    "2018-03-22 13:15:39.753236: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
    "2018-03-22 13:15:40.177364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \n",
    "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
    "pciBusID: 0000:8a:00.0\n",
    "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
    "2018-03-22 13:15:40.177411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:8a:00.0, compute capability: 3.7)\n",
    "2018-03-22 13:15:41.758993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:8a:00.0, compute capability: 3.7)\n",
    "Training\n",
    "Iteration 0: with minibatch training loss = 4.29 and accuracy of 0.14\n",
    "Iteration 500: with minibatch training loss = 1.33 and accuracy of 0.53\n",
    "Epoch 1, Overall loss = 1.31 and accuracy of 0.53\n",
    "Iteration 1000: with minibatch training loss = 1.16 and accuracy of 0.62\n",
    "Iteration 1500: with minibatch training loss = 0.809 and accuracy of 0.75\n",
    "Epoch 2, Overall loss = 0.882 and accuracy of 0.69\n",
    "Iteration 2000: with minibatch training loss = 0.579 and accuracy of 0.78\n",
    "Epoch 3, Overall loss = 0.707 and accuracy of 0.753\n",
    "Iteration 2500: with minibatch training loss = 0.72 and accuracy of 0.75\n",
    "Iteration 3000: with minibatch training loss = 0.717 and accuracy of 0.78\n",
    "Epoch 4, Overall loss = 0.594 and accuracy of 0.794\n",
    "Iteration 3500: with minibatch training loss = 0.722 and accuracy of 0.73\n",
    "Epoch 5, Overall loss = 0.51 and accuracy of 0.82\n",
    "Iteration 4000: with minibatch training loss = 0.312 and accuracy of 0.92\n",
    "Iteration 4500: with minibatch training loss = 0.346 and accuracy of 0.86\n",
    "Epoch 6, Overall loss = 0.441 and accuracy of 0.846\n",
    "Iteration 5000: with minibatch training loss = 0.355 and accuracy of 0.86\n",
    "Epoch 7, Overall loss = 0.377 and accuracy of 0.869\n",
    "Iteration 5500: with minibatch training loss = 0.359 and accuracy of 0.89\n",
    "Iteration 6000: with minibatch training loss = 0.142 and accuracy of 0.97\n",
    "Epoch 8, Overall loss = 0.318 and accuracy of 0.888\n",
    "Iteration 6500: with minibatch training loss = 0.299 and accuracy of 0.88\n",
    "Epoch 9, Overall loss = 0.272 and accuracy of 0.904\n",
    "Iteration 7000: with minibatch training loss = 0.332 and accuracy of 0.89\n",
    "Iteration 7500: with minibatch training loss = 0.21 and accuracy of 0.92\n",
    "Epoch 10, Overall loss = 0.229 and accuracy of 0.919\n",
    "Iteration 8000: with minibatch training loss = 0.186 and accuracy of 0.94\n",
    "Epoch 11, Overall loss = 0.203 and accuracy of 0.929\n",
    "Iteration 8500: with minibatch training loss = 0.123 and accuracy of 0.97\n",
    "Iteration 9000: with minibatch training loss = 0.25 and accuracy of 0.92\n",
    "Epoch 12, Overall loss = 0.174 and accuracy of 0.94\n",
    "Iteration 9500: with minibatch training loss = 0.159 and accuracy of 0.92\n",
    "Epoch 13, Overall loss = 0.156 and accuracy of 0.946\n",
    "Iteration 10000: with minibatch training loss = 0.133 and accuracy of 0.94\n",
    "Iteration 10500: with minibatch training loss = 0.244 and accuracy of 0.92\n",
    "Epoch 14, Overall loss = 0.141 and accuracy of 0.951\n",
    "Iteration 11000: with minibatch training loss = 0.182 and accuracy of 0.94\n",
    "Epoch 15, Overall loss = 0.123 and accuracy of 0.957\n",
    "Validation\n",
    "Epoch 1, Overall loss = 1.08 and accuracy of 0.79\n",
    "Test\n",
    "Epoch 1, Overall loss = 1.16 and accuracy of 0.763"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report your work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an architecture of:\n",
    "    \n",
    "Layer 1: Conv2D (5x5x64)\n",
    "\n",
    "    Batch Norm\n",
    "    Max Pool (3x3, Stride of 2)   \n",
    "Layer 2: \n",
    "\n",
    "    Conv2D (5x5x64)\n",
    "    Batch Norm\n",
    "    Max Pool (3x3, Stride of 2)    \n",
    "Layer 3: \n",
    "\n",
    "    Conv2d (3x3x128)\n",
    "    Relu\n",
    "    Batch Norm (Empirical evidence showed that it raised accuracy if placed after Relu activation here, then before)   \n",
    "Layer 4: \n",
    "\n",
    "    Conv2d (3x3x128)\n",
    "    Relu (No Batch Norm here, empirical evidence showed that it lowered accuracy)   \n",
    "Layer 5: \n",
    "\n",
    "    Conv2d (3x3x128)\n",
    "    Relu\n",
    "    Batch Norm    \n",
    "    Max Pool (3x3, Stride of 2)    \n",
    "Layer 6: \n",
    "\n",
    "    Fully Connected (Output 384), Relu Activation\n",
    "Layer 7: \n",
    "\n",
    "    Fully Connected (Output 192), Relu Activation\n",
    "Out Layer: \n",
    "\n",
    "    Fully Connected (Output 10)\n",
    "\n",
    "Optimizer: AdamOptimizer(.001) (when I tried RMSPropOptimizer, the loss increased (by 0.66) and the accuracy dropped (by .077). Similarly, GradientDescentOptimizer, Adagrad, Adadelta and others performed worse for me than AdamOptimizer)\n",
    "\n",
    "Loss: Cross Entropy Loss\n",
    "\n",
    "Learning Rate: 0.001 – I tried adjusting it, and I found that this ended up having the best accuracy with m\n",
    "\n",
    "I got various results for *Validation*, based on how many epochs I ran it for:\n",
    "\n",
    "    6 Epochs: Overall loss = 0.852 and accuracy of 0.757\n",
    "    10 Epochs: Overall loss = 0.923 and accuracy of 0.765\n",
    "    30 Epochs: Overall loss = 1.22 and accuracy of 0.795\n",
    "    100 Epochs: Overall loss = 1.51 and accuracy of 0.831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecuture was built, based off of a model on Github (https://github.com/exelban/tensorflow-cifar-10), with some adjustments. I used batch normalization, instead of the LRN they used. I played with the learning rate, as well as various elements of the networks, trying various sizes of conv layers (both kernel sizes, as well as number of kernels), adding and removing some max pools (including strides), and adding in some other regularization. In the end, I found that this had a fairly good result, with some variance. I typically ran it for 6 epochs to try it out, and then 30 if I wanted a fairly good test. I originally tried using the tensorflow basic model, though I found that it didn't have fantastic accuracy, and gradually built up until I found that this model worked fairly well. I spent a fair amount of time playing with some different optimizers as well, and AdamOptimizer had a fair advantage over the ones I tried. \n",
    "\n",
    "I found that the length of this architecture was pretty good, allowing the network to learn a lot from the images, and upped my accuracy by a fair percentage. At the same time, because we were dealing with CIFAR-10 images, a longer network didn't seem to work as well, because the original images were small enough that extending it didn't really help validation accuracy much. One thing that I hope to implement in the future is creating more images, by adapting some of the original cifar10 images, so that I can make a larger dataset, and see if I can train a more robust, larger network with that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report your Test Accuracy - Only do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-6156a0791212>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-6156a0791212>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Validation:\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Validation:\n",
    "    Epoch 1, Overall loss = 1.08 and accuracy of 0.79\n",
    "Test:\n",
    "    Epoch 1, Overall loss = 1.16 and accuracy of 0.763"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it for 15 epochs (with a shortage of XSEDE resources, I was running short on time), I got a validation accuracy of .79 and a test accuracy of 0.763. It was relatively similar, which was nice to see, though the test accuracy was still smaller than the validation accuracy, which makes sense. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
